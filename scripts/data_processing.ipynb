{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462c2421-5606-4aa1-b126-20739ee174e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import mkdir\n",
    "from os.path import isdir\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.signal import savgol_filter\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6dfeda-ceae-45e2-9077-bf983e409ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/clariostar/legend.csv\", \"w\") as csv_legend:\n",
    "    with open(\"../data/clariostar/legend.tsf\", \"r\") as legendfile:\n",
    "        for line in legendfile.readlines():\n",
    "            line = line.rstrip().split(\" \")\n",
    "            text = line[0] + \",\"\n",
    "            csv_legend.write(text)\n",
    "            for index, element in enumerate(line):\n",
    "\n",
    "                if index != 0:\n",
    "                    if element != \"\":\n",
    "    \n",
    "                        if index+1 != len(line):\n",
    "                            element = element + \" \" \n",
    "                            csv_legend.write(element)\n",
    "                        else:\n",
    "                            csv_legend.write(element + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e27a7d-3705-450e-897f-c362bb24c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = pd.read_csv(\"../data/clariostar/legend.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb61898-18e9-4f51-84f3-25eaa3911f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_dict = {}\n",
    "for media in legend[\"M_Number\"]:\n",
    "    legend_dict[media] = legend[legend[\"M_Number\"] == media][\"BMM9 variant\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d871d9b-af87-4ad3-9067-558d2f9dd633",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''read_clariostar_table\n",
    "\n",
    "    Function for reading a csv file.\n",
    "\n",
    "    :param dataframe_path\n",
    "        :type str\n",
    "    :param separator\n",
    "        :type str\n",
    "    :param lines_to_skip\n",
    "        :type int\n",
    "\n",
    "'''\n",
    "def read_clariostar_table(dataframe_path:str,separator:str,lines_to_skip:int)->pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(dataframe_path,sep=separator,skiprows=lines_to_skip)\n",
    "    except Exception as e:\n",
    "        raise Exception(\"[-] ERROR reading dataframe with exception: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33deb56b-6ea9-4c4a-a71c-adb2546ddab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''read_layout\n",
    "\n",
    "    This function reads the layout dataframe and returns a dictionary with\n",
    "    content information for each well and a dictionary with media and blank association.\n",
    "    \n",
    "'''\n",
    "def read_layout(layout:pd.DataFrame)->tuple:\n",
    "    try:\n",
    "        layout_dict = {}\n",
    "        blank_vals = []\n",
    "        media_vals = []\n",
    "        for index in layout.index:\n",
    "            for row_index, media_name in enumerate(layout.loc[index,:]):\n",
    "                layout_row = index + \"0\" + str(row_index+1)\n",
    "                content = media_name\n",
    "                layout_dict[layout_row] = media_name\n",
    "\n",
    "                if \"M\" in media_name and media_name not in media_vals:\n",
    "                    media_vals.append(media_name)\n",
    "                elif \"B\" in media_name and media_name not in blank_vals:\n",
    "                    blank_vals.append(media_name)\n",
    "\n",
    "        media_blank_dict = {}\n",
    "        for media in media_vals:\n",
    "            media_number = int(media.split(\"M\")[-1])\n",
    "            for blank in blank_vals:\n",
    "                blank_number = int(blank.split(\"B\")[-1])\n",
    "                if media_number == blank_number:\n",
    "                    media_blank_dict[media] = blank\n",
    "                    break\n",
    "            if media not in list(media_blank_dict.keys()):\n",
    "                raise Exception(\"[-] ERROR there is no blank for media: {}\".format(media))\n",
    "        return layout_dict, media_blank_dict\n",
    "    except Exception as e:\n",
    "        raise Exception(\"[-] ERROR during creation of layout_dict with exception: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b73414-9ff2-48aa-b8ee-179929a826d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''create_od_gfp_dataframes\n",
    "\n",
    "    This function takes the raw dataframe and the layout_dict dictionary to \n",
    "    create new columns that can be used to assess the data for OD600 and GFP.\n",
    "    This data is within the rows: \"Raw Data (600 1)\" and \"Raw Data (470-15 2)\".\n",
    "    The function also calculates BLANK values for each experimental unit and \n",
    "    finally produces blank corrected datasets for each experiment, which are \n",
    "    returned in form of dictionaries.\n",
    "    \n",
    "'''\n",
    "def create_od_gfp_dataframes(dataframe:pd.DataFrame,layout_dict:dict,blank_dict:dict)->tuple:\n",
    "    try:\n",
    "        print(\"[*] Creating OD/GFP dataframe dictionaries\")\n",
    "        data = dataframe.copy()\n",
    "\n",
    "        # get row index of content, group and well rows\n",
    "        content_index = data.index[data.iloc[:,0] == \"Content\"].to_list()\n",
    "        group_index = data.index[data.iloc[:,0] == \"Group\"].to_list()\n",
    "        well_index = data.index[data.iloc[:,0] == \"Well\"].to_list()\n",
    "        if len(content_index) != 1:\n",
    "            raise Exception(\"[-] There are multiple Content indexes in the dataframe!\")\n",
    "        if len(group_index) != 1:\n",
    "            raise Exception(\"[-] There are multiple Group indexes in the dataframe!\")\n",
    "        if len(well_index) != 1:\n",
    "            raise Exception(\"[-] There are multiple Well indexes in the dataframe!\")\n",
    "\n",
    "        # rename columns based on well row and layout dict\n",
    "        new_columns = []\n",
    "        for col in data.loc[:,:].columns:\n",
    "            well_value = data[col].loc[well_index[0]]\n",
    "            if well_value in list(layout_dict.keys()):\n",
    "                new_col = layout_dict[well_value]\n",
    "            else:\n",
    "                new_col = col\n",
    "            new_columns.append(new_col)\n",
    "        print(\"[*] Setting up new columns\")\n",
    "        data.columns = new_columns\n",
    "\n",
    "        # get OD and GFP data\n",
    "        od_data = data[data[\"Unnamed: 0\"] == \"Raw Data (600 1)\"]\n",
    "        gfp_data = data[data[\"Unnamed: 0\"] == 'Raw Data (470-15 2)']\n",
    "\n",
    "        # get a list of unique media entries\n",
    "        print(\"[*] Creating list of unique experiments\")\n",
    "        media_entries = []\n",
    "        for key in layout_dict.keys():\n",
    "            media = layout_dict[key]\n",
    "            if \"M\" in media:\n",
    "                if media not in media_entries:\n",
    "                    media_entries.append(media)\n",
    "\n",
    "        # loop over each media data and create blank corrected dataframes\n",
    "        od_dict = {}\n",
    "        gfp_dict = {}\n",
    "        print(\"[*] Looping over unique media entries (experiments)\")\n",
    "        for media in media_entries:\n",
    "            blank = blank_dict[media]\n",
    "            blank_data_od = od_data[blank].astype(float)\n",
    "            blank_data_gfp = gfp_data[blank].astype(float)\n",
    "            \n",
    "            media_data_od = od_data[media].astype(float)\n",
    "            media_data_gfp = gfp_data[media].astype(float)\n",
    "            \n",
    "            # calculate BLANK values as mean values\n",
    "            if type(blank_data_gfp) == pd.Series:\n",
    "                blank_od = blank_data_od[:50].mean()\n",
    "                blank_gfp = blank_data_gfp[:50].mean()\n",
    "            else:\n",
    "                blank_od = blank_data_od.mean(axis=1)[:50].mean()\n",
    "                blank_gfp = blank_data_gfp.mean(axis=1)[:50].mean()\n",
    "\n",
    "            print(\"\\t[*] BLANK value OD600 for media {} is {}\".format(media, blank_od))\n",
    "            print(\"\\t[*] BLANK value GFP is {}\".format(blank_gfp))\n",
    "            media_data_od_blank_corrected = media_data_od - blank_od\n",
    "            media_data_gfp_blank_corrected = media_data_gfp - blank_gfp\n",
    "\n",
    "            media_data_od_blank_corrected.index = list(range(1,media_data_od_blank_corrected.index.size+1,1))\n",
    "            media_data_gfp_blank_corrected.index = list(range(1,media_data_gfp_blank_corrected.index.size+1,1))\n",
    "            \n",
    "            od_dict[media] = media_data_od_blank_corrected\n",
    "            gfp_dict[media] = media_data_gfp_blank_corrected\n",
    "            \n",
    "        return od_dict, gfp_dict\n",
    "    except Exception as e:\n",
    "        raise Exception(\"[-] ERROR creating od/gfp dataframe with exception: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4306459-da87-419a-b8af-b3d123333f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plot_od_gfp\n",
    "\n",
    "    This function takes the od_dict and gfp_dict produced by the \n",
    "    create_od_gfp_dataframes function and creates basic overview plots.\n",
    "    The save path is composed of the media and date value.\n",
    "\n",
    "'''\n",
    "def plot_od_gfp(od_data_dict:dict,gfp_data_dict:dict,date:str)->int:\n",
    "    try:\n",
    "        print(\"[*] Saving plots in ../results/figures/clariostar/{}/*\".format(date))\n",
    "        savep = \"../results/figures/clariostar/{}/\".format(date)\n",
    "        if isdir(savep) == False:\n",
    "            print(\"\\t[*] Directory does not yet exist, creating directory: {}\".format(savep))\n",
    "            mkdir(savep)\n",
    "            \n",
    "        print(\"[*] Looping over keys and plotting data ...\")\n",
    "        for media in od_data_dict.keys():\n",
    "            od_data = od_data_dict[media]\n",
    "            gfp_data = gfp_data_dict[media]\n",
    "\n",
    "            if od_data.empty != True:\n",
    "                time = (od_data.index.to_numpy() * 10)/60\n",
    "                time = time.round(2)\n",
    "                x_index = od_data.index.to_numpy()\n",
    "                time = time[::40]\n",
    "                x_index = x_index[::40]\n",
    "    \n",
    "                mean_od_values = od_data.mean(axis=1)\n",
    "                mean_std_values = od_data.std(axis=1)\n",
    "                x_index_mean = od_data.index.to_numpy()\n",
    "                \n",
    "                plt.figure(figsize=(8,6))\n",
    "                plt.plot(od_data, color=\"blue\",alpha=0.5)\n",
    "                plt.errorbar(x_index_mean[::40],\n",
    "                             mean_od_values[::40],\n",
    "                             yerr=mean_std_values[::40],\n",
    "                             ecolor=\"red\",capsize=5, color=\"red\")\n",
    "                plt.xticks(x_index,time)\n",
    "                plt.title(media + \": \" + legend_dict[media], fontsize=10)\n",
    "                plt.xlabel(\"time in hours [h]\")\n",
    "                plt.ylabel(\"blank corrected OD600\")\n",
    "                plt.ylim(-0.2,3.0)\n",
    "                plt.grid()\n",
    "                plot_path = savep + media + \"_od_data.svg\"\n",
    "                plt.savefig(plot_path,dpi=300)\n",
    "                plt.close()\n",
    "            else:\n",
    "                print(\"\\t[WARNING] There is no OD data available for {}\".format(media))\n",
    "            if gfp_data.empty != True:\n",
    "                time = (gfp_data.index.to_numpy() * 10)/60\n",
    "                time = time.round(2)\n",
    "                x_index = gfp_data.index.to_numpy()\n",
    "                time = time[::40]\n",
    "                x_index = x_index[::40]\n",
    "                \n",
    "                plt.figure(figsize=(8,6))\n",
    "                plt.plot(gfp_data, color=\"green\")\n",
    "                plt.xticks(x_index,time)\n",
    "                plt.title(media + \": \" + legend_dict[media], fontsize=10)\n",
    "                plt.xlabel(\"time in hours [h]\")\n",
    "                plt.ylabel(\"blank corrected GFP RFU\")\n",
    "                plt.grid()\n",
    "                plot_path = savep + media + \"_gfp_data.svg\"\n",
    "                plt.savefig(plot_path,dpi=300)\n",
    "                plt.close()\n",
    "            else:\n",
    "                print(\"\\t[WARNING] There is no GFP data available for {}\".format(media))\n",
    "\n",
    "        print(\"[+] DONE\")\n",
    "        return 1\n",
    "    except Exception as e:\n",
    "        raise Exception(\"[-] ERROR creating basic OD/GFP plots with exception: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a9cdb7-f2bf-402c-9042-37fe3dc1ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_savgol_filter_on_data_dict(data_dict:dict)->dict:\n",
    "    try:\n",
    "        print(\"[+] Trying to apply savgol filter to dataframe ...\")\n",
    "        filtered_dict = {}\n",
    "        for key in data_dict.keys():\n",
    "\n",
    "            od_data_columns = data_dict[key].columns\n",
    "            new_cols = list(range(len(od_data_columns)))\n",
    "            data_dict[key].columns = new_cols\n",
    "            \n",
    "            temp_dict = {}\n",
    "            for col in data_dict[key].columns:\n",
    "                temp_dict[col] = savgol_filter(data_dict[key][col],50,1)\n",
    "            \n",
    "            temp_df = pd.DataFrame(temp_dict)\n",
    "            print(\"\\t[*] Adjusting Index DataFrame: {}\".format(key))\n",
    "            temp_df.index = np.array(range(1,len(data_dict[key][col]) + 1))*10\n",
    "            print(\"\\t[*] Replacing NaN values with -2.0\")\n",
    "            #temp_df = temp_df.fillna(-2.0)\n",
    "            temp_df.columns = od_data_columns\n",
    "            filtered_dict[key] = temp_df\n",
    "\n",
    "        print(\"[+] DONE\")\n",
    "        return filtered_dict\n",
    "    except Exception as e:\n",
    "        raise Exception(\"[-] ERROR during savgol filter applying with exception: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed15b10e-7469-4d47-8334-5450d4422ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_od_data_dict(od_data:dict)->dict:\n",
    "    try:\n",
    "        print(\"[+] Starting to transform OD data dictionary\")\n",
    "\n",
    "\n",
    "        for key in od_data.keys():\n",
    "            print(\"\\t[*] Working with: {}\".format(key))\n",
    "        \n",
    "            od_data_columns = od_data[key].columns\n",
    "            new_cols = list(range(len(od_data_columns)))\n",
    "            od_data[key].columns = new_cols\n",
    "            \n",
    "            new_data_dict = {}\n",
    "            for col in od_data[key].columns:\n",
    "                # od_data[key][col] = od_data[key][col].apply(lambda x: 0.0 if )\n",
    "                new_data_column = od_data[key][col] - min(od_data[key][col])\n",
    "                new_data_dict[col] = new_data_column\n",
    "            od_data[key] = pd.DataFrame(new_data_dict)\n",
    "            od_data[key].columns = od_data_columns\n",
    "\n",
    "            \n",
    "        print(\"[+] DONE\")\n",
    "        return od_data\n",
    "    except Exception as e:\n",
    "        raise Exception(\"[-] ERROR during transformation of od_data with exception: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb2dc3-50d9-45c3-a3d0-62da0654c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_regression(data_dict:dict, steps=50)->tuple:\n",
    "    try:\n",
    "        print(\"[+] Starting plotting procedure with slope extension ...\")\n",
    "        lineregress_dict = {}\n",
    "        slope_dict = {}\n",
    "        for key in data_dict.keys():\n",
    "            print(\"\\t[*] Working with sample: {}\".format(key))\n",
    "            mean_arr = data_dict[key].mean(axis=1).to_numpy()\n",
    "            x_arr = np.array(range(1,len(mean_arr)+1)) * 10\n",
    "            #mean_value_dict[key] = mean_arr\n",
    "            \n",
    "            lineregress_dict[key] = {}\n",
    "            slope_dict[key] = {}\n",
    "            for column in data_dict[key].columns:\n",
    "                \n",
    "                data_column = data_dict[key][column].to_numpy()\n",
    "                \n",
    "                start = 0\n",
    "                temp_end = steps\n",
    "                end = 1200\n",
    "                step = steps\n",
    "\n",
    "                results_lineregress = []\n",
    "                slope_entries = []\n",
    "                print(\"\\t[*] Collecting slope data for each: {} steps\".format(step))\n",
    "                while(start < end):\n",
    "                    sliced_arr_y = data_column[start:temp_end]\n",
    "                    sliced_arr_x = x_arr[start:temp_end]\n",
    "                    if len(sliced_arr_y) != 0:\n",
    "                        res = stats.linregress(x=sliced_arr_x,y=sliced_arr_y)\n",
    "\n",
    "                        results_lineregress.append((start, temp_end, res.slope, res.intercept))\n",
    "                        slope_entries.append(res.slope)\n",
    "                    start += step\n",
    "                    temp_end += step\n",
    "\n",
    "                lineregress_dict[key][column] = results_lineregress\n",
    "                slope_dict[key][column] = slope_entries\n",
    "        return lineregress_dict, slope_dict\n",
    "    except Exception as e:\n",
    "        raise Exception(\"[-] ERROR with exception: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0003bcf1-b53b-471e-bbc8-396c547214ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_dict_to_log10(data_dict:dict)->dict:\n",
    "    try:\n",
    "        print(\"[+] Trying to transform dataframe ...\")\n",
    "        log_data_dict = {}\n",
    "        \n",
    "        for key in data_dict.keys():\n",
    "            log_data_dict[key] = np.log10(data_dict[key])\n",
    "            log_data_dict[key] = log_data_dict[key].apply(lambda col: col.fillna(col.min()))\n",
    "\n",
    "        print(\"[+] DONE\")\n",
    "        return log_data_dict\n",
    "    except Exception as e:\n",
    "        raise Exception(\"[-] ERROR during data transformation with exception: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05747fbb-02cc-4ddf-a200-c28120916ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_generation_times(log_data_dict:dict,start_od=0.3, end_od=0.4)->pd.DataFrame:\n",
    "    try:\n",
    "        print(\"[+] Starting to calculate generation times ...\")\n",
    "        generation_time_dict = {}\n",
    "        \n",
    "        for key in log_data_dict.keys():\n",
    "            \n",
    "            generation_time_dict[key] = []\n",
    "            \n",
    "            old_cols = log_data_dict[key].columns\n",
    "            new_cols = list(range(len(old_cols)))\n",
    "            log_data_dict[key].columns = new_cols\n",
    "            \n",
    "            for col in log_data_dict[key].columns:\n",
    "                end_index = -500\n",
    "                start_index = -500\n",
    "                switch_0 = False\n",
    "                switch_1 = False\n",
    "                for index, value in enumerate(log_data_dict[key][col]):\n",
    "                    if value >= np.log10(start_od) and switch_0 == False:\n",
    "                        start_val = value\n",
    "                        start_index = index\n",
    "                        switch_0 = True\n",
    "                    if value >= np.log10(end_od) and switch_1 == False:\n",
    "                        end_val = value\n",
    "                        end_index = index\n",
    "                        switch_1 = True\n",
    "                if end_index == -500 or start_index == -500:\n",
    "                    generation_time = 0.0\n",
    "                else:\n",
    "                    slope_time = (end_index - start_index) * 10\n",
    "                    n = ((end_val - start_val)/np.log10(2))\n",
    "                    generation_time = slope_time / n\n",
    "                generation_time_dict[key].append(generation_time)\n",
    "            log_data_dict[key].columns = old_cols\n",
    "            #print(generation_time_dict)\n",
    "        \n",
    "        generation_time_df = pd.DataFrame.from_dict(generation_time_dict, orient='index').transpose()\n",
    "\n",
    "        print(\"[+] DONE\")\n",
    "        return generation_time_df\n",
    "    except Exception as e:\n",
    "        raise Exception(\"[-] ERROR calculating generation times with exception: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c10df8b-1e2a-4d72-876b-e57bee537a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generation_time(generation_time_data:pd.DataFrame, date:str, filename:str)->int:\n",
    "    try:\n",
    "        print(\"[+] Plotting generation time boxplots for {}\".format(date))\n",
    "        savep = \"../results/figures/clariostar/{}/{}\".format(date, filename)\n",
    "        box_props = dict(color=\"black\", linewidth=2)\n",
    "        median_props = dict(color=\"red\")\n",
    "        whisker_props = dict(color=\"black\")\n",
    "        \n",
    "        ax = gtime_data.boxplot(grid=False, boxprops=box_props, medianprops=median_props, whiskerprops=whisker_props)\n",
    "        \n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        plt.ylim(0,10)\n",
    "        plt.savefig(savep, dpi=300)\n",
    "        plt.close()\n",
    "        print(\"[+] DONE\")\n",
    "        return 1\n",
    "    except Exception as e:\n",
    "        raise Exception(\"[-] ERROR creating generation time boxplots with exception: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1da605-4d2d-423e-bbe4-b5821a504ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_max_od(max_od_dataframe:pd.DataFrame, date:str, filename:str)->int:\n",
    "    try:\n",
    "        print(\"[+] Plotting maximum OD boxplots for {}\".format(date))\n",
    "        savep = \"../results/figures/clariostar/{}/{}\".format(date, filename)\n",
    "        box_props = dict(color=\"black\", linewidth=2)\n",
    "        median_props = dict(color=\"red\")\n",
    "        whisker_props = dict(color=\"black\")\n",
    "        \n",
    "        ax = max_od_dataframe.boxplot(grid=False, boxprops=box_props, medianprops=median_props, whiskerprops=whisker_props)\n",
    "        \n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        plt.ylim(0,3.0)\n",
    "        plt.savefig(savep, dpi=300)\n",
    "        plt.close()\n",
    "        print(\"[+] DONE\")\n",
    "        return 1\n",
    "    except Exception as e:\n",
    "        raise Exception(\"[-] ERROR creating maximum OD boxplots with exception: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efecc7a2-88e9-438c-b6e6-b6491f1e7371",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/clariostar/data_files/\"\n",
    "data_layout_dict = {}\n",
    "dates = []\n",
    "for date in listdir(data_path):\n",
    "    date = date.split(\"_clariostar_\")[0]\n",
    "    if date not in dates:\n",
    "        dates.append(date)\n",
    "        data_layout_dict[date] = (data_path + date+\"_clariostar_data.CSV\", data_path + date + \"_clariostar_layout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b74c20d-7000-4162-a615-c714557dac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_od_data_dict = {}\n",
    "all_gfp_data_dict = {}\n",
    "all_gtime_data_dict = {}\n",
    "summary_gtime_data = {}\n",
    "for date in data_layout_dict:\n",
    "    print(\"[*] WORKING ON DATE: {}\".format(date))\n",
    "    path_to_data = data_layout_dict[date][0]\n",
    "    path_to_layout = data_layout_dict[date][1]\n",
    "    \n",
    "    data = read_clariostar_table(path_to_data,separator=\";\",lines_to_skip=5)\n",
    "    layout = pd.read_csv(path_to_layout, sep=\";\", index_col=0)\n",
    "    \n",
    "    layout_dict, media_blank_dict = read_layout(layout)\n",
    "    od_dict, gfp_dict = create_od_gfp_dataframes(data,layout_dict,media_blank_dict)\n",
    "\n",
    "    # restricting time to 66h\n",
    "    for key in od_dict.keys():\n",
    "        od_dict[key] = od_dict[key].iloc[:460,:]\n",
    "        gfp_dict[key] = gfp_dict[key].iloc[:460,:]\n",
    "    \n",
    "    # plot_od_gfp(od_dict, gfp_dict, date)\n",
    "    all_od_data_dict[date] = od_dict\n",
    "    all_gfp_data_dict[date] = gfp_dict\n",
    "    \n",
    "    od_data = transform_od_data_dict(all_od_data_dict[date])\n",
    "    od_data = apply_savgol_filter_on_data_dict(od_data)\n",
    "    log_data_dict = transform_data_dict_to_log10(od_data)\n",
    "    gtime = calculate_generation_times(log_data_dict, start_od=0.05, end_od=0.1)\n",
    "    gtime_data = np.round(gtime/60, 2)\n",
    "    # plot_generation_time(gtime_data, date, \"generation_time_005_01.svg\")\n",
    "\n",
    "    gtime = calculate_generation_times(log_data_dict, start_od=0.1, end_od=0.4)\n",
    "    gtime_data = np.round(gtime/60, 2)\n",
    "    # plot_generation_time(gtime_data, date, \"generation_time_01_04.svg\")\n",
    "\n",
    "    for col in gtime_data.columns:\n",
    "        if col not in list(summary_gtime_data.keys()):\n",
    "            summary_gtime_data[col] = gtime_data[col].to_list()\n",
    "        else:\n",
    "            for val in gtime_data[col]:\n",
    "                summary_gtime_data[col].append(val)\n",
    "    \n",
    "    all_gtime_data_dict[date] = gtime_data\n",
    "\n",
    "    max_od_dict = {}\n",
    "    for media in od_dict.keys():\n",
    "        max_values = od_dict[media].max()\n",
    "        # max_std = max_values.std()\n",
    "        max_od_dict[media] = max_values\n",
    "    \n",
    "    max_od_dataframe = pd.DataFrame.from_dict(max_od_dict)\n",
    "    plot_max_od(max_od_dataframe,date,\"max_od.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6692d8c2-b16b-4b70-abb4-4ec95382fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(summary_gtime_data.keys())\n",
    "values = list(summary_gtime_data.values())\n",
    "\n",
    "box_props = dict(color=\"black\", linewidth=2)\n",
    "median_props = dict(color=\"red\")\n",
    "whisker_props = dict(color=\"black\")\n",
    "\n",
    "boxplot_values = []\n",
    "for vallist in values:\n",
    "    boxplot_values.append([x for x in vallist if np.isnan(x) == False])\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "boxplot= plt.boxplot(boxplot_values, labels=labels, manage_ticks=True, \n",
    "                     boxprops=box_props, medianprops=median_props, whiskerprops=whisker_props)\n",
    "\n",
    "xticks = plt.xticks(rotation=90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
